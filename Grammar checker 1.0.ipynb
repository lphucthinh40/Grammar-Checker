{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('He', 'PPS'), ('want', 'VB'), ('to', 'TO'), ('eat', 'VB'), ('ice', 'JJ-HL'), ('cream', 'NN-HL')], [('a', 'AT'), ('birds', 'NNS'), ('is', 'BEZ'), ('laying', 'VBG'), ('eggs', 'NNS-HL')], [('I', 'PPSS'), ('feel', 'VB'), ('interesting', 'VBG-HL')], [('when', 'WRB'), ('I', 'PPSS'), ('will', 'MD'), ('play', 'VB'), ('soccer', 'NN-HL')], [('I', 'PPSS'), ('will', 'MD'), ('played', 'VBN'), ('chess', 'NN'), ('tomorrow', 'NR')], [('before', 'IN'), ('played', 'VBN'), (',', ','), ('I', 'PPSS'), ('need', 'VB'), ('to', 'TO'), ('warm', 'VB'), ('up', 'RP')], [('how', 'WRB'), ('much', 'AP'), ('steps', 'NNS'), ('is', 'BEZ'), ('necessary', 'JJ')], [('The', 'AT'), ('dog', 'NN'), (',', ','), ('who', 'WPS'), ('is', 'BEZ'), ('chewing', 'VBG'), ('on', 'IN'), ('my', 'PP$'), ('jeans', 'NNS'), (',', ','), ('is', 'BEZ'), ('usually', 'RB'), ('very', 'QL'), ('good', 'JJ'), ('.', '.')], [('There', 'EX'), ('is', 'BEZ'), ('a', 'AT'), ('problem', 'NN'), ('with', 'IN'), ('the', 'AT'), ('balance', 'NN'), ('sheet', 'NN-HL')], [('The', 'AT'), ('colors', 'NNS'), ('and', 'CC'), ('the', 'AT'), ('rainbow', 'NN'), ('are', 'BER'), ('beautiful', 'JJ')]]\n",
      "He/PPS want/VB to/TO eat/VB ice/JJ-HL cream/NN-HL\n",
      "a/AT birds/NNS is/BEZ laying/VBG eggs/NNS-HL\n",
      "I/PPSS feel/VB interesting/VBG-HL\n",
      "when/WRB I/PPSS will/MD play/VB soccer/NN-HL\n",
      "I/PPSS will/MD played/VBN chess/NN tomorrow/NR\n",
      "before/IN played/VBN ,/, I/PPSS need/VB to/TO warm/VB up/RP\n",
      "how/WRB much/AP steps/NNS is/BEZ necessary/JJ\n",
      "The/AT dog/NN ,/, who/WPS is/BEZ chewing/VBG on/IN my/PP$ jeans/NNS ,/, is/BEZ usually/RB very/QL good/JJ ./.\n",
      "There/EX is/BEZ a/AT problem/NN with/IN the/AT balance/NN sheet/NN-HL\n",
      "The/AT colors/NNS and/CC the/AT rainbow/NN are/BER beautiful/JJ\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re    \n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from  nltk.corpus import brown\n",
    "from nltk import load\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# POS TAGGER\n",
    "# Using a pre-trained Conditional Random Field POS tag model\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def pos_features(sentence, i):\n",
    "    current = sentence[i]\n",
    "\n",
    "    # previous word\n",
    "    if (i>0):\n",
    "        prev_w = sentence[i-1]\n",
    "    else:\n",
    "        prev_w = \"<START>\"\n",
    "\n",
    "    # next word\n",
    "    if (i<len(sentence)-1):\n",
    "        next_w = sentence[i+1]\n",
    "    else:\n",
    "        next_w = \"<END>\"\n",
    "\n",
    "    # generate feature sets\n",
    "    features = {\n",
    "        \"word\": current,\n",
    "        \"next_word\": next_w,\n",
    "        \"prev_word\": prev_w,\n",
    "        \"suffix(1)\": current[-1:],\n",
    "        \"suffix(2)\": current[-2:],\n",
    "        \"suffix(3)\": current[-3:],\n",
    "        \"prefix(1)\": current[0],\n",
    "        \"prefix(2)\": current[:2],\n",
    "        \"prefix(3)\": current[:3],\n",
    "        \"prev_suffix(1)\": prev_w[-1:],\n",
    "        \"prev_suffix(2)\": prev_w[-2:],\n",
    "        \"prev_suffix(3)\": prev_w[-3:],\n",
    "        \"prev_prefix(1)\": prev_w[0],\n",
    "        \"prev_prefix(2)\": prev_w[:2],\n",
    "        \"prev_prefix(3)\": prev_w[:3],\n",
    "        \"next_suffix(1)\": next_w[-1:],\n",
    "        \"next_suffix(2)\": next_w[-2:],\n",
    "        \"next_suffix(3)\": next_w[-3:],\n",
    "        \"next_prefix(1)\": next_w[0],\n",
    "        \"next_prefix(2)\": next_w[:2],\n",
    "        \"next_prefix(3)\": next_w[:3],\n",
    "        'is_first': i == 0,\n",
    "        'is_last': i == len(sentence) - 1,\n",
    "        'curr_is_title': current.istitle(),\n",
    "        'prev_is_title': prev_w.istitle(),\n",
    "        'next_is_title': next_w.istitle(),\n",
    "        'curr_is_lower': current.islower(),\n",
    "        'prev_is_lower': prev_w.islower(),\n",
    "        'next_is_lower': next_w.islower(),\n",
    "        'curr_is_upper': current.isupper(),\n",
    "        'prev_is_upper': prev_w.isupper(),\n",
    "        'next_is_upper': next_w.isupper(),\n",
    "        'curr_is_digit': current.isdigit(),\n",
    "        'prev_is_digit': prev_w.isdigit(),\n",
    "        'next_is_digit': next_w.isdigit()\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# example:\n",
    "sents = [\"He want to eat ice cream\", \"a birds is laying eggs\", \"I feel interesting\", \n",
    "         \"when I will play soccer\", \"I will played chess tomorrow\",\n",
    "         \"before played, I need to warm up\", \"how much steps is necessary\", \"The dog, who is chewing on my jeans, is usually very good.\",\n",
    "         \"There is a problem with the balance sheet\", \"The colors and the rainbow are beautiful\"]\n",
    "\n",
    "# prepocessing\n",
    "sents = [nltk.word_tokenize(sent) for sent in sents]  # Tokenization\n",
    "sent2feature = [[pos_features(sent,i) for i in range(len(sent))] for sent in sents] \n",
    "# load crf model\n",
    "crf = joblib.load('POStagger.joblib')\n",
    "\n",
    "# tagging \n",
    "tagged_sents = []\n",
    "labels = crf.predict(sent2feature) \n",
    "for i in range(len(sents)):\n",
    "    tagged_sent = list(zip(sents[i], labels[i]))\n",
    "    tagged_sents.append(tagged_sent)\n",
    "\n",
    "\n",
    "print(tagged_sents)\n",
    "formatted_sents = [['/'.join([a,b]) for (a,b) in sent] for sent in tagged_sents]\n",
    "formatted_sents = [' '.join(sent) for sent in formatted_sents]\n",
    "for sent in formatted_sents:\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP He/PRP) (VP want/VBP to/TO eat/VB) (NP ice/NN cream/NN))\n",
      "(S (NP a/DT birds/NNS) (VP is/VBZ laying/VBG) (NP eggs/NNS))\n",
      "(S (NP I/PRP) (VP feel/VBP interesting/VBG))\n",
      "(S when/WRB (NP I/PRP) (VP will/MD play/VB) (NP soccer/NN))\n",
      "(S (NP I/PRP) (VP will/MD played/VB) (NP chess/NN tomorrow/NN))\n",
      "(S\n",
      "  (PP before/IN)\n",
      "  (NP played/VBN)\n",
      "  ,/,\n",
      "  (NP I/PRP)\n",
      "  (VP need/VBP to/TO warm/VB)\n",
      "  up/RP)\n",
      "(S how/WRB (NP much/JJ steps/NNS) (VP is/VBZ) (NP necessary/JJ))\n",
      "(S\n",
      "  (NP The/DT dog/NN)\n",
      "  ,/,\n",
      "  (NP who/WP)\n",
      "  (VP is/VBZ chewing/VBG)\n",
      "  (PP on/IN)\n",
      "  (NP my/PRP$ jeans/NNS)\n",
      "  ,/,\n",
      "  (VP is/VBZ usually/RB)\n",
      "  very/RB\n",
      "  (NP good/JJ)\n",
      "  ./.)\n",
      "(S\n",
      "  (NP There/EX)\n",
      "  (VP is/VBZ)\n",
      "  (NP a/DT problem/NN)\n",
      "  (PP with/IN)\n",
      "  (NP the/DT balance/NN sheet/NN))\n",
      "(S\n",
      "  (NP The/DT colors/NNS)\n",
      "  and/CC\n",
      "  (NP the/DT rainbow/NN)\n",
      "  (VP are/VBP)\n",
      "  (NP beautiful/JJ))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# ---------------------------------\n",
    "# POS CHUNKER\n",
    "# Use NLTK_train chunker based on corpus conll2000 for now\n",
    "# ---------------------------------\n",
    "chunker = pickle.load(open(\"conll2000_ub.pickle\", 'rb'))\n",
    "chunked_sents = [chunker.parse(tagged_list) for tagged_list in tagged_lists] \n",
    "for chunked_sent in chunked_sents:\n",
    "    print(chunked_sent) \n",
    "# NOTE: chunked_sent is a NLTK tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# GRAMMAR CHECKER\n",
    "# ---------------------------------\n",
    "\n",
    "# Writting grammar rules \n",
    "grammar_rules = [ r\"(?P<E1>(((a|an)/DT)|(one/CD))(\\s\\w+/(JJ))*\\s\\w+/(NNS))\",   # plural noun detected after 'a', 'an' or 'one'\n",
    "                  r\"(?P<E2>many/JJ(\\s\\w+/(JJ))*\\s\\w+/NN(?!S))\",               # singular noun detected after 'many'\n",
    "                  r\"(?P<E3>(?<!the/DT)\\s\\w+/JJS)\",                            # missing 'the' before superlative\n",
    "                  r\"(?P<E4>(feels*|felt)/VB\\w\\s(\\w+/(RB|JJ)\\s)*\\w+ing/VBG)\", # \"feel/felt\" should not be followed by 'adj-ing'\n",
    "                  r\"(?P<E5>\\w+/MD\\s\\w+(((s|ed)/VB\\w*)|/VB\\w))\",             # modal verb should be followed by a base-form verb\n",
    "                  r\"(?P<E6>\\w+/(NN|NNP|PRP|PPS)\\s\\w+/VB(?!Z))\",            # sigular noun requires verb with '-s' or '-es'\n",
    "                  r\"(?P<E7>(is|are|were|was|been)/VB\\w\\s\\w+/(VB(\\s|$)|VBZ|VBP))\",  # passive required verb with '-ed'\n",
    "                  r\"(?P<E8>when/WRB\\s\\w+/\\w+\\s(will|shall)/MD)\",   # \"when\" clause should be in present tense                ]   \n",
    "                  r\"(?P<E9>(before|after)/\\w+\\s\\w+/VB(?!G))\",       # expecting a verb-ing after preposition \n",
    "                  r\"(?P<E10>how/\\w+\\smuch/\\w+\\s\\w+/(NNS|NNPS))\"    # use \"many\" for plural nouns instead of \"much\"\n",
    "                  r\"(?P<E11>how/\\w+\\smany/\\w+\\s\\w+/(NN\\s|NNP\\s))\"    # use \"many\" for plural nouns instead of \"much\"\n",
    "\n",
    "                ]\n",
    "\n",
    "messages = {\"E1\":  (lambda x: \"{} -> plural noun detected after singular determinant\".format(x)),\n",
    "            \"E2\":  (lambda x: \"{} -> singular noun detected after 'many'\".format(x)),\n",
    "            \"E3\":  (lambda x: \"{} -> missing 'the' before superlative\".format(x)),\n",
    "            \"E4\":  (lambda x: \"{} -> 'feel/felt' should not be followed by 'adj-ing'\".format(x)),\n",
    "            \"E5\":  (lambda x: \"{} -> modal verb should be followed by a base-form verb\".format(x)),\n",
    "            \"E6\":  (lambda x: \"{} -> sigular noun requires verb with '-s' or '-es'\".format(x)),\n",
    "            \"E7\":  (lambda x: \"{} -> passive required verb with '-ed'\".format(x)),\n",
    "            \"E8\":  (lambda x: \"{} -> 'when' clause should be in present tense\".format(x)),\n",
    "            \"E9\":  (lambda x: \"{} -> expecting a verb-ing after preposition\".format(x)),\n",
    "            \"E10\": (lambda x: \"{} -> use 'many' for plural nouns instead of 'much'\".format(x)),\n",
    "            \"E11\": (lambda x: \"{} -> use 'much' for non-plural nouns instead of 'many'\".format(x))\n",
    "\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will/MD played/VBN -> modal verb should be followed by a base-form verb\n",
      "He/PPS want/VB -> sigular noun requires verb with '-s' or '-es'\n",
      "when/WRB I/PPSS will/MD -> 'when' clause should be in present tense\n",
      "before/IN played/VB -> expecting a verb-ing after preposition\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(grammar_rules)):\n",
    "    pattern = re.compile(grammar_rules[i])\n",
    "    results = [pattern.search(sent) for sent in formatted_sents]\n",
    "    for result in results:\n",
    "        if result is not None:\n",
    "            key = ''.join(result.groupdict().keys())\n",
    "            print(messages[key](result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
