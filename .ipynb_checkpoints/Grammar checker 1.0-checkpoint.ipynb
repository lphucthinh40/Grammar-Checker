{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized sentence:\n",
      "[['He', 'want', 'to', 'eat', 'ice', 'cream'], ['a', 'birds', 'is', 'laying', 'eggs'], ['I', 'feel', 'interesting'], ['when', 'I', 'will', 'play', 'soccer'], ['I', 'will', 'played', 'chess', 'tomorrow'], ['before', 'played', ',', 'I', 'need', 'to', 'warm', 'up'], ['how', 'much', 'steps', 'is', 'necessary']]\n",
      "\n",
      "tagged list:\n",
      "[[('He', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('eat', 'VB'), ('ice', 'NN'), ('cream', 'NN')], [('a', 'DT'), ('birds', 'NNS'), ('is', 'VBZ'), ('laying', 'VBG'), ('eggs', 'NNS')], [('I', 'PRP'), ('feel', 'VBP'), ('interesting', 'VBG')], [('when', 'WRB'), ('I', 'PRP'), ('will', 'MD'), ('play', 'VB'), ('soccer', 'NN')], [('I', 'PRP'), ('will', 'MD'), ('played', 'VB'), ('chess', 'NN'), ('tomorrow', 'NN')], [('before', 'IN'), ('played', 'VBN'), (',', ','), ('I', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('warm', 'VB'), ('up', 'RP')], [('how', 'WRB'), ('much', 'JJ'), ('steps', 'NNS'), ('is', 'VBZ'), ('necessary', 'JJ')]]\n",
      "\n",
      "tagged sentences:\n",
      "['He/PRP want/VBP to/TO eat/VB ice/NN cream/NN', 'a/DT birds/NNS is/VBZ laying/VBG eggs/NNS', 'I/PRP feel/VBP interesting/VBG', 'when/WRB I/PRP will/MD play/VB soccer/NN', 'I/PRP will/MD played/VB chess/NN tomorrow/NN', 'before/IN played/VBN ,/, I/PRP need/VBP to/TO warm/VB up/RP', 'how/WRB much/JJ steps/NNS is/VBZ necessary/JJ']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re    \n",
    "\n",
    "from  nltk.corpus import brown\n",
    "from nltk import load\n",
    "\n",
    "# ---------------------------------\n",
    "# POS TAGGER\n",
    "# Using nltk default tagger for now \n",
    "# ---------------------------------\n",
    "# example:\n",
    "sents = [\"He want to eat ice cream\", \"a birds is laying eggs\", \"I feel interesting\", \n",
    "         \"when I will play soccer\", \"I will played chess tomorrow\",\n",
    "         \"before played, I need to warm up\", \"how much steps is necessary\"]\n",
    "sents = [nltk.word_tokenize(sent) for sent in sents]  # Tokenization\n",
    "tagged_lists = [nltk.pos_tag(sent) for sent in sents] # Using default Tagger by NLTK \n",
    "tagged_sents = [['/'.join([a,b]) for (a,b) in sent] for sent in tagged_lists]\n",
    "tagged_sents = [' '.join(sent) for sent in tagged_sents]\n",
    "\n",
    "\n",
    "# check result:\n",
    "print (\"tokenized sentence:\\n{0}\\n\".format(sents))\n",
    "print (\"tagged list:\\n{0}\\n\".format(tagged_lists))\n",
    "print (\"tagged sentences:\\n{0}\".format(tagged_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk_trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b5c2012a3813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Use NLTK_train chunker based on corpus conll2000 for now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# ---------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mchunker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conll2000_ub.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mchunked_sents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchunker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtagged_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged_lists\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchunked_sent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunked_sents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk_trainer'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# ---------------------------------\n",
    "# POS CHUNKER\n",
    "# Use NLTK_train chunker based on corpus conll2000 for now\n",
    "# ---------------------------------\n",
    "chunker = pickle.load(open(\"conll2000_ub.pickle\", 'rb'))\n",
    "chunked_sents = [chunker.parse(tagged_list) for tagged_list in tagged_lists] \n",
    "for chunked_sent in chunked_sents:\n",
    "    print(chunked_sent) \n",
    "\n",
    "# NOTE: chunked_sent is a NLTK tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# GRAMMAR CHECKER\n",
    "# ---------------------------------\n",
    "\n",
    "# Writting grammar rules \n",
    "grammar_rules = [ r\"(?P<E1>(((a|an)/DT)|(one/CD))(\\s\\w+/(JJ))*\\s\\w+/(NNS))\",   # plural noun detected after 'a', 'an' or 'one'\n",
    "                  r\"(?P<E2>many/JJ(\\s\\w+/(JJ))*\\s\\w+/NN(?!S))\",               # singular noun detected after 'many'\n",
    "                  r\"(?P<E3>(?<!the/DT)\\s\\w+/JJS)\",                            # missing 'the' before superlative\n",
    "                  r\"(?P<E4>(feels*|felt)/VB\\w\\s(\\w+/(RB|JJ)\\s)*\\w+ing/VBG)\", # \"feel/felt\" should not be followed by 'adj-ing'\n",
    "                  r\"(?P<E5>\\w+/MD\\s\\w+(((s|ed)/VB\\w*)|/VB\\w))\",             # modal verb should be followed by a base-form verb\n",
    "                  r\"(?P<E6>\\w{2,}/(NN|NNP|PRP)\\s\\w+/VB(?!Z))\",            # sigular noun requires verb with '-s' or '-es'\n",
    "                  r\"(?P<E7>(is|are|were|was|been)/VB\\w\\s\\w+/(VB(\\s|$)|VBZ|VBP))\",  # passive required verb with '-ed'\n",
    "                  r\"(?P<E8>when/WRB\\s\\w+/\\w+\\s(will|shall)/MD)\",   # \"when\" clause should be in present tense                ]   \n",
    "                  r\"(?P<E9>(before|after)/\\w+\\s\\w+/VB(?!G))\",       # expecting a verb-ing after preposition \n",
    "                  r\"(?P<E10>how/\\w+\\smuch/\\w+\\s\\w+/(NNS|NNPS))\"    # use \"many\" for plural nouns instead of \"much\"\n",
    "                  r\"(?P<E11>how/\\w+\\smany/\\w+\\s\\w+/(NN\\s|NNP\\s))\"    # use \"many\" for plural nouns instead of \"much\"\n",
    "\n",
    "                ]\n",
    "\n",
    "messages = {\"E1\":  (lambda x: \"{} -> plural noun detected after singular determinant\".format(x)),\n",
    "            \"E2\":  (lambda x: \"{} -> singular noun detected after 'many'\".format(x)),\n",
    "            \"E3\":  (lambda x: \"{} -> missing 'the' before superlative\".format(x)),\n",
    "            \"E4\":  (lambda x: \"{} -> 'feel/felt' should not be followed by 'adj-ing'\".format(x)),\n",
    "            \"E5\":  (lambda x: \"{} -> modal verb should be followed by a base-form verb\".format(x)),\n",
    "            \"E6\":  (lambda x: \"{} -> sigular noun requires verb with '-s' or '-es'\".format(x)),\n",
    "            \"E7\":  (lambda x: \"{} -> passive required verb with '-ed'\".format(x)),\n",
    "            \"E8\":  (lambda x: \"{} -> 'when' clause should be in present tense\".format(x)),\n",
    "            \"E9\":  (lambda x: \"{} -> expecting a verb-ing after preposition\".format(x)),\n",
    "            \"E10\": (lambda x: \"{} -> use 'many' for plural nouns instead of 'much'\".format(x))\n",
    "            \"E11\": (lambda x: \"{} -> use 'much' for non-plural nouns instead of 'many'\".format(x))\n",
    "\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a/DT cars/NNS -> plural noun detected after singular determinant\n",
      "feel/VBP interesting/VBG -> 'feel/felt' should not be followed by 'adj-ing'\n",
      "will/MD played/VB -> modal verb should be followed by a base-form verb\n",
      "He/PRP want/VB -> sigular noun requires verb with '-s' or '-es'\n",
      "when/WRB I/PRP will/MD -> 'when' clause should be in present tense\n",
      "before/IN played/VB -> expecting a verb-ing after preposition\n",
      "how/WRB much/JJ steps/NNS -> use 'many' for plural nouns instead of 'much'\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(grammar_rules)):\n",
    "    pattern = re.compile(grammar_rules[i])\n",
    "    results = [pattern.search(sent) for sent in tagged_sents]\n",
    "    for result in results:\n",
    "        if result is not None:\n",
    "            key = ''.join(result.groupdict().keys())\n",
    "            print(messages[key](result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
